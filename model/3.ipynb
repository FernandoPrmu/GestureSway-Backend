{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e2423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow-serving-api==2.8.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (2.8.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (0.10.9)\n",
      "Requirement already satisfied: pygame in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (2.5.2)\n",
      "Requirement already satisfied: flask in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: grpcio<2,>=1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-serving-api==2.8.0) (1.62.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-serving-api==2.8.0) (3.20.3)\n",
      "Requirement already satisfied: tensorflow<3,>=2.8.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-serving-api==2.8.0) (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (2.1.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from mediapipe) (3.7.2)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click>=8.0->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->flask) (2.1.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (23.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.31.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.15.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.2.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.28.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (2024.2.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\appdata\\roaming\\python\\python311\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow<3,>=2.8.0->tensorflow-serving-api==2.8.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow-serving-api==2.8.0 opencv-python mediapipe pygame flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e255fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pygame\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "718451c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'SolutionOutputs' has no attribute 'multi_hand_landmarks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 183\u001b[0m\n\u001b[0;32m    180\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[4], line 146\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Process frame for gesture recognition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m image, results \u001b[38;5;241m=\u001b[39m mediapipe_detection(frame, holistic)\n\u001b[1;32m--> 146\u001b[0m gesture_label \u001b[38;5;241m=\u001b[39m recognize_gesture(results)\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Integrate gesture recognition with the game\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gesture_label \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopenPlam\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[1;32mIn[4], line 112\u001b[0m, in \u001b[0;36mrecognize_gesture\u001b[1;34m(results)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecognize_gesture\u001b[39m(results):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m    113\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m hand_landmarks \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m    114\u001b[0m             landmarks \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'SolutionOutputs' has no attribute 'multi_hand_landmarks'"
     ]
    }
   ],
   "source": [
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the screen\n",
    "SCREEN_WIDTH = 800\n",
    "SCREEN_HEIGHT = 600\n",
    "BLOCK_SIZE = 20\n",
    "GRID_WIDTH = SCREEN_WIDTH // BLOCK_SIZE\n",
    "GRID_HEIGHT = SCREEN_HEIGHT // BLOCK_SIZE\n",
    "FPS = 10\n",
    "\n",
    "screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "pygame.display.set_caption(\"Snake Game\")\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Colors\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "RED = (255, 0, 0)\n",
    "\n",
    "\n",
    "\n",
    "# Snake class\n",
    "class Snake:\n",
    "    gesture_labels = ['openPlam','closeFist','openPlamToLeft','openPlamToRight']\n",
    "    def __init__(self):\n",
    "        self.length = 1\n",
    "        self.positions = [((SCREEN_WIDTH / 2), (SCREEN_HEIGHT / 2))]\n",
    "        self.direction = random.choice([UP, DOWN, LEFT, RIGHT])\n",
    "        self.color = RED\n",
    "\n",
    "    def get_head_position(self):\n",
    "        return self.positions[0]\n",
    "\n",
    "    def turn(self, point):\n",
    "        if self.length > 1 and (point[0]*-1, point[1]*-1) == self.direction:\n",
    "            return\n",
    "        else:\n",
    "            self.direction = point\n",
    "\n",
    "    def move(self):\n",
    "        cur = self.get_head_position()\n",
    "        x, y = self.direction\n",
    "        new = (((cur[0] + (x*BLOCK_SIZE)) % SCREEN_WIDTH), (cur[1] + (y*BLOCK_SIZE)) % SCREEN_HEIGHT)\n",
    "        if len(self.positions) > 2 and new in self.positions[2:]:\n",
    "            self.reset()\n",
    "        else:\n",
    "            self.positions.insert(0, new)\n",
    "            if len(self.positions) > self.length:\n",
    "                self.positions.pop()\n",
    "\n",
    "    def reset(self):\n",
    "        self.length = 1\n",
    "        self.positions = [((SCREEN_WIDTH / 2), (SCREEN_HEIGHT / 2))]\n",
    "        self.direction = random.choice([UP, DOWN, LEFT, RIGHT])\n",
    "\n",
    "    def draw(self, surface):\n",
    "        for p in self.positions:\n",
    "            r = pygame.Rect((p[0], p[1]), (BLOCK_SIZE, BLOCK_SIZE))\n",
    "            pygame.draw.rect(surface, self.color, r)\n",
    "            pygame.draw.rect(surface, WHITE, r, 1)\n",
    "\n",
    "#     def handle_keys(self):\n",
    "#         for event in pygame.event.get():\n",
    "#             if event.type == pygame.QUIT:\n",
    "#                 pygame.quit()\n",
    "#             elif event.type == pygame.KEYDOWN:\n",
    "#                 if event.key == pygame.K_UP:\n",
    "#                     self.turn(UP)\n",
    "#                 elif event.key == pygame.K_DOWN:\n",
    "#                     self.turn(DOWN)\n",
    "#                 elif event.key == pygame.K_LEFT:\n",
    "#                     self.turn(LEFT)\n",
    "#                 elif event.key == pygame.K_RIGHT:\n",
    "#                     self.turn(RIGHT)\n",
    "                    \n",
    "    def handle_keys(self,handGesture):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if  gesture_label[0] == handGesture:\n",
    "                    self.turn(UP)\n",
    "                elif gesture_label[1] == handGesture:\n",
    "                    self.turn(DOWN)\n",
    "                elif gesture_label[2] == handGesture:\n",
    "                    self.turn(LEFT)\n",
    "                elif gesture_label[3] == handGesture:\n",
    "                    self.turn(RIGHT)\n",
    "\n",
    "# Gesture recognition setup\n",
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "\n",
    "# TensorFlow model for gesture recognition\n",
    "# Replace this with your trained model\n",
    "model = tf.keras.models.load_model('action.hdf5')\n",
    "\n",
    "# # Define gesture labels\n",
    "# gesture_labels = {0: 'openPlam', 1: 'closeFist',2: 'openPlamToLeft',3:'openPlamToRight'}\n",
    "\n",
    "# Function to preprocess the hand image\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "    image.flags.writeable = False                  # Image is no longer writeable\n",
    "    results = model.process(image)                 # Make prediction\n",
    "    image.flags.writeable = True                   # Image is now writeable \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "    return image, results\n",
    "\n",
    "# Gesture recognition function\n",
    "def recognize_gesture(results):\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for point in hand_landmarks.landmark:\n",
    "                landmarks.append([point.x, point.y, point.z])\n",
    "            landmarks = np.array(landmarks, dtype=np.float32).reshape(1, -1)\n",
    "            prediction = model.predict(landmarks)\n",
    "            label = gesture_labels[np.argmax(prediction)]\n",
    "            return label\n",
    "    return None\n",
    "\n",
    "# Direction constants\n",
    "UP = (0, -1)\n",
    "DOWN = (0, 1)\n",
    "LEFT = (-1, 0)\n",
    "RIGHT = (1, 0)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    snake = Snake()\n",
    "    food = pygame.Rect(random.randint(0, GRID_WIDTH - 1) * BLOCK_SIZE,\n",
    "                       random.randint(0, GRID_HEIGHT - 1) * BLOCK_SIZE,\n",
    "                       BLOCK_SIZE, BLOCK_SIZE)\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # Set mediapipe model \n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Process frame for gesture recognition\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            gesture_label = recognize_gesture(results)\n",
    "\n",
    "            # Integrate gesture recognition with the game\n",
    "            if gesture_label == 'openPlam':\n",
    "                snake.handle_keys(gesture_label)\n",
    "            elif gesture_label =='closeFist':\n",
    "                snake.handle_keys(gesture_label)\n",
    "            elif gesture_label == 'openPlamToLeft':\n",
    "                snake.handle_keys(gesture_label)\n",
    "            elif gesture_label == 'openPlamToRight':\n",
    "                snake.handle_keys(gesture_label)\n",
    "\n",
    "            # Draw the snake and food on the Pygame screen\n",
    "            screen.fill(BLACK)\n",
    "            snake.move()\n",
    "            snake.draw(screen)\n",
    "            pygame.draw.rect(screen, WHITE, food)\n",
    "            pygame.display.update()\n",
    "            clock.tick(FPS)\n",
    "\n",
    "            # Check if snake ate the food\n",
    "            if snake.get_head_position() == food.topleft:\n",
    "                snake.length += 1\n",
    "                food = pygame.Rect(random.randint(0, GRID_WIDTH - 1) * BLOCK_SIZE,\n",
    "                                   random.randint(0, GRID_HEIGHT - 1) * BLOCK_SIZE,\n",
    "                                   BLOCK_SIZE, BLOCK_SIZE)\n",
    "\n",
    "            # Check for Pygame events\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "\n",
    "# Initialize Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the screen\n",
    "SCREEN_WIDTH = 800\n",
    "SCREEN_HEIGHT = 600\n",
    "BLOCK_SIZE = 20\n",
    "GRID_WIDTH = SCREEN_WIDTH // BLOCK_SIZE\n",
    "GRID_HEIGHT = SCREEN_HEIGHT // BLOCK_SIZE\n",
    "FPS = 10\n",
    "\n",
    "screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "pygame.display.set_caption(\"Snake Game\")\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Colors\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "RED = (255, 0, 0)\n",
    "\n",
    "# Snake class\n",
    "class Snake:\n",
    "    def __init__(self):\n",
    "        self.length = 1\n",
    "        self.positions = [((SCREEN_WIDTH / 2), (SCREEN_HEIGHT / 2))]\n",
    "        self.direction = random.choice([UP, DOWN, LEFT, RIGHT])\n",
    "        self.color = RED\n",
    "\n",
    "    def get_head_position(self):\n",
    "        return self.positions[0]\n",
    "\n",
    "    def turn(self, point):\n",
    "        if self.length > 1 and (point[0]*-1, point[1]*-1) == self.direction:\n",
    "            return\n",
    "        else:\n",
    "            self.direction = point\n",
    "\n",
    "    def move(self):\n",
    "        cur = self.get_head_position()\n",
    "        x, y = self.direction\n",
    "        new = (((cur[0] + (x*BLOCK_SIZE)) % SCREEN_WIDTH), (cur[1] + (y*BLOCK_SIZE)) % SCREEN_HEIGHT)\n",
    "        if len(self.positions) > 2 and new in self.positions[2:]:\n",
    "            self.reset()\n",
    "        else:\n",
    "            self.positions.insert(0, new)\n",
    "            if len(self.positions) > self.length:\n",
    "                self.positions.pop()\n",
    "\n",
    "    def reset(self):\n",
    "        self.length = 1\n",
    "        self.positions = [((SCREEN_WIDTH / 2), (SCREEN_HEIGHT / 2))]\n",
    "        self.direction = random.choice([UP, DOWN, LEFT, RIGHT])\n",
    "\n",
    "    def draw(self, surface):\n",
    "        for p in self.positions:\n",
    "            r = pygame.Rect((p[0], p[1]), (BLOCK_SIZE, BLOCK_SIZE))\n",
    "            pygame.draw.rect(surface, self.color, r)\n",
    "            pygame.draw.rect(surface, WHITE, r, 1)\n",
    "\n",
    "    def handle_keys(self):\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_UP:\n",
    "                    self.turn(UP)\n",
    "                elif event.key == pygame.K_DOWN:\n",
    "                    self.turn(DOWN)\n",
    "                elif event.key == pygame.K_LEFT:\n",
    "                    self.turn(LEFT)\n",
    "                elif event.key == pygame.K_RIGHT:\n",
    "                    self.turn(RIGHT)\n",
    "\n",
    "# Gesture recognition setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# TensorFlow model for gesture recognition\n",
    "# Replace this with your trained model\n",
    "model = tf.keras.models.load_model('action.hdf5')\n",
    "\n",
    "# Define gesture labels\n",
    "gesture_labels = {0: 'Fist', 1: 'Open'}\n",
    "\n",
    "# Function to preprocess the hand image\n",
    "def preprocess_image(image):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.flip(image, 1)\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return results, image\n",
    "\n",
    "# Gesture recognition function\n",
    "def recognize_gesture(results):\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for point in hand_landmarks.landmark:\n",
    "                landmarks.append([point.x, point.y, point.z])\n",
    "            landmarks = np.array(landmarks, dtype=np.float32).reshape(1, -1)\n",
    "            prediction = model.predict(landmarks)\n",
    "            label = gesture_labels[np.argmax(prediction)]\n",
    "            return label\n",
    "    return None\n",
    "\n",
    "# Direction constants\n",
    "UP = (0, -1)\n",
    "DOWN = (0, 1)\n",
    "LEFT = (-1, 0)\n",
    "RIGHT = (1, 0)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    snake = Snake()\n",
    "    food = pygame.Rect(random.randint(0, GRID_WIDTH - 1) * BLOCK_SIZE,\n",
    "                       random.randint(0, GRID_HEIGHT - 1) * BLOCK_SIZE,\n",
    "                       BLOCK_SIZE, BLOCK_SIZE)\n",
    "    while True:\n",
    "        screen.fill(BLACK)\n",
    "        snake.handle_keys()\n",
    "        snake.move()\n",
    "        snake.draw(screen)\n",
    "\n",
    "        pygame.draw.rect(screen, WHITE, food)\n",
    "        pygame.display.update()\n",
    "        clock.tick(FPS)\n",
    "\n",
    "        # Gesture recognition\n",
    "        ret, frame = cap.read()\n",
    "        results, _ = preprocess_image(frame)\n",
    "        gesture_label = recognize_gesture(results)\n",
    "        \n",
    "        if gesture_label == 'Fist':\n",
    "            snake.turn(UP)\n",
    "        elif gesture_label == 'Open':\n",
    "            snake.turn(DOWN)\n",
    "\n",
    "        if snake.get_head_position() == food.topleft:\n",
    "            snake.length += 1\n",
    "            food = pygame.Rect(random.randint(0, GRID_WIDTH - 1) * BLOCK_SIZE,\n",
    "                               random.randint(0, GRID_HEIGHT - 1) * BLOCK_SIZE,\n",
    "                               BLOCK_SIZE, BLOCK_SIZE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c40e759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
